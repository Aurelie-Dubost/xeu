{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283e425a-4df5-4c66-93a0-b1cfd2548127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import percentileofscore\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from vol_data import *\n",
    "from surface import *\n",
    "import pickle\n",
    "import pprint\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c625b577-0572-49db-8b35-85efd9163965",
   "metadata": {},
   "source": [
    "#### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b1352b6-1192-4156-9617-733505ba314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vol_moneyness(udl_list, matu_list, moneyness_list, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generate random volatility moneyness data.\n",
    "    \"\"\"\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "    data = {\n",
    "        (udl, matu, mon): np.random.rand(len(date_range)) * 100\n",
    "        for udl in udl_list\n",
    "        for matu in matu_list\n",
    "        for mon in moneyness_list\n",
    "    }\n",
    "    df = pd.DataFrame(data, index=date_range)\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.columns, names=['udl', 'matu', 'moneyness'])\n",
    "    return df\n",
    "\n",
    "def get_vol_delta(udl_list, matu_list, delta_list, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generate random volatility delta data.\n",
    "    \"\"\"\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "    data = {\n",
    "        (udl, matu, delta): np.random.rand(len(date_range)) * 100\n",
    "        for udl in udl_list\n",
    "        for matu in matu_list\n",
    "        for delta in delta_list\n",
    "    }\n",
    "    df = pd.DataFrame(data, index=date_range)\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.columns, names=['udl', 'matu', 'delta'])\n",
    "    return df\n",
    "    \n",
    "def generate_table(udl_list, matu_list, moneyness_list, delta_list, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generate random volatility data for moneyness and delta in a single step and create a structured DataFrame.\n",
    "\n",
    "    Args:\n",
    "        udl_list (list): List of underlying assets.\n",
    "        matu_list (list): List of maturities.\n",
    "        moneyness_list (list): List of moneyness levels.\n",
    "        delta_list (list): List of delta levels.\n",
    "        start_date (str): Start date for the data.\n",
    "        end_date (str): End date for the data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with combined moneyness and delta data, indexed by date with MultiIndex columns.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date_range = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "\n",
    "        # Generate moneyness and delta data\n",
    "        df_vol_moneyness = get_vol_moneyness(udl_list, matu_list, moneyness_list, start_date, end_date)\n",
    "        df_vol_delta = get_vol_delta(udl_list, matu_list, delta_list, start_date, end_date)\n",
    "\n",
    "        data = {}\n",
    "\n",
    "        # Combine moneyness data\n",
    "        for udl in udl_list:\n",
    "            for matu in matu_list:\n",
    "                for mon in moneyness_list:\n",
    "                    key = (udl, matu, mon)\n",
    "                    data[(udl, 'IV', matu, mon)] = df_vol_moneyness[key]\n",
    "\n",
    "        # Combine delta data\n",
    "        for udl in udl_list:\n",
    "            for matu in matu_list:\n",
    "                for delta in delta_list:\n",
    "                    key = (udl, matu, delta)\n",
    "                    data[(udl, 'IVFD', matu, delta)] = df_vol_delta[key]\n",
    "\n",
    "        df = pd.DataFrame(data, index=date_range)\n",
    "        df.columns = pd.MultiIndex.from_tuples(df.columns, names=['udl', 'param', 'matu', 'value'])\n",
    "        df.index.name = 'Date'\n",
    "        df.ffill(inplace=True)\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during table generation: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def df_to_nested_dict(df):\n",
    "    nested_dict = {}\n",
    "    for date, row in df.iterrows():\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        nested_dict[date_str] = {}\n",
    "        for col, val in row.items():\n",
    "            udl, param, matu, value = col\n",
    "            nested_dict[date_str].setdefault(udl, {}).setdefault(param, {}).setdefault(matu, {})[value] = val\n",
    "    return nested_dict\n",
    "\n",
    "def sanity_check_surface(df, computed_surface, udl, date, moneyness_levels, surface_type):\n",
    "    date_range = pd.date_range(start=df.index.min(), end=date, freq='B')\n",
    "    df_filtered = df.loc[date_range]\n",
    "\n",
    "    for matu in computed_surface.index:\n",
    "        for mon in moneyness_levels:\n",
    "            col_name = f'{mon}'\n",
    "            if col_name in computed_surface.columns:\n",
    "                values = df_filtered.xs((udl, 'IV', matu, mon), level=['udl', 'param', 'matu', 'value'], axis=1).dropna().values.flatten()\n",
    "                if len(values) > 0:\n",
    "                    if surface_type == 'percentile':\n",
    "                        expected_value = percentileofscore(values, df.loc[date, (udl, 'IV', matu, mon)], kind='mean')\n",
    "                    elif surface_type == 'zscore':\n",
    "                        mean = values.mean()\n",
    "                        std = values.std(ddof=1)\n",
    "                        expected_value = (df.loc[date, (udl, 'IV', matu, mon)] - mean) / std if std > 0 else np.nan\n",
    "                    else:\n",
    "                        continue\n",
    "                    computed_value = computed_surface.at[matu, col_name]\n",
    "                    if not np.isclose(expected_value, computed_value, atol=1e-2, equal_nan=True):\n",
    "                        print(f\"Mismatch at Maturity: {matu}, Moneyness: {mon}. Expected {surface_type.capitalize()}: {expected_value}, Computed {surface_type.capitalize()}: {computed_value}\")\n",
    "                        return False\n",
    "    return True\n",
    "    \n",
    "    \n",
    "def calculate_percentile_rank_surface(nested_dict, udl, date, moneyness_levels):\n",
    "    try:\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        percentile_rank_surface = pd.DataFrame(index=moneyness_levels, columns=nested_dict[date_str][udl]['IV'].keys())\n",
    "\n",
    "        for matu in percentile_rank_surface.columns:\n",
    "            for mon in moneyness_levels:\n",
    "                try:\n",
    "                    values = []\n",
    "                    for past_date in nested_dict:\n",
    "                        if udl in nested_dict[past_date] and 'IV' in nested_dict[past_date][udl] and matu in nested_dict[past_date][udl]['IV'] and mon in nested_dict[past_date][udl]['IV'][matu]:\n",
    "                            values.append(nested_dict[past_date][udl]['IV'][matu][mon])\n",
    "                    if len(values) > 0:\n",
    "                        current_value = nested_dict[date_str][udl]['IV'][matu][mon]\n",
    "                        percentile = percentileofscore(values, current_value, kind='mean')\n",
    "                        percentile_rank_surface.at[mon, matu] = percentile\n",
    "                    else:\n",
    "                        percentile_rank_surface.at[mon, matu] = np.nan\n",
    "                except KeyError:\n",
    "                    percentile_rank_surface.at[mon, matu] = np.nan\n",
    "\n",
    "        return percentile_rank_surface.T\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in calculate_percentile_rank_surface: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def calculate_zscore_surface(nested_dict, udl, date, moneyness_levels):\n",
    "    try:\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        zscore_surface = pd.DataFrame(index=moneyness_levels, columns=nested_dict[date_str][udl]['IV'].keys())\n",
    "\n",
    "        for matu in zscore_surface.columns:\n",
    "            for mon in moneyness_levels:\n",
    "                try:\n",
    "                    values = []\n",
    "                    for past_date in nested_dict:\n",
    "                        if udl in nested_dict[past_date] and 'IV' in nested_dict[past_date][udl] and matu in nested_dict[past_date][udl]['IV'] and mon in nested_dict[past_date][udl]['IV'][matu]:\n",
    "                            values.append(nested_dict[past_date][udl]['IV'][matu][mon])\n",
    "                    if len(values) > 0:\n",
    "                        mean = np.mean(values)\n",
    "                        std = np.std(values, ddof=1)\n",
    "                        current_value = nested_dict[date_str][udl]['IV'][matu][mon]\n",
    "                        if std > 0:\n",
    "                            zscore = (current_value - mean) / std\n",
    "                            zscore_surface.at[mon, matu] = zscore\n",
    "                        else:\n",
    "                            zscore_surface.at[mon, matu] = np.nan\n",
    "                    else:\n",
    "                        zscore_surface.at[mon, matu] = np.nan\n",
    "                except KeyError:\n",
    "                    zscore_surface.at[mon, matu] = np.nan\n",
    "\n",
    "        return zscore_surface.T\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in calculate_zscore_surface: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def plot_surface(udl, date, surface_type, start_date=None, end_date=None):\n",
    "    try:\n",
    "        date = pd.Timestamp(date)\n",
    "\n",
    "        if surface_type == 'Level':\n",
    "            vol_surface = create_vol_surface(nested_dict, date, udl, moneyness_list)\n",
    "            vol_surface = ensure_numerical(vol_surface)  # Ensure numerical format\n",
    "            display(style_df(vol_surface, \"Volatility Surface\"))\n",
    "        elif surface_type == 'Percentile':\n",
    "            if start_date and end_date:\n",
    "                start_date = pd.Timestamp(start_date)\n",
    "                end_date = pd.Timestamp(end_date)\n",
    "                if start_date > end_date:\n",
    "                    print(\"Start date cannot be after end date.\")\n",
    "                    return\n",
    "                filtered_dict = {k: v for k, v in nested_dict.items() if start_date <= pd.Timestamp(k) <= end_date}\n",
    "                percentile_surface = calculate_percentile_rank_surface(filtered_dict, udl, end_date, moneyness_list)\n",
    "                percentile_surface = ensure_numerical(percentile_surface)  # Ensure numerical format\n",
    "                title = f\"Percentile Surface ({udl}) From: {start_date.strftime('%Y-%m-%d')} to: {end_date.strftime('%Y-%m-%d')}\"\n",
    "                styled_df = style_df(percentile_surface, title)\n",
    "                display(styled_df)\n",
    "            else:\n",
    "                print(\"Please select start and end dates for Percentile surface.\")\n",
    "        elif surface_type == 'Z-score':\n",
    "            if start_date and end_date:\n",
    "                start_date = pd.Timestamp(start_date)\n",
    "                end_date = pd.Timestamp(end_date)\n",
    "                if start_date > end_date:\n",
    "                    print(\"Start date cannot be after end date.\")\n",
    "                    return\n",
    "                filtered_dict = {k: v for k, v in nested_dict.items() if start_date <= pd.Timestamp(k) <= end_date}\n",
    "                zscore_surface = calculate_zscore_surface(filtered_dict, udl, end_date, moneyness_list)\n",
    "                zscore_surface = ensure_numerical(zscore_surface)  # Ensure numerical format\n",
    "                title = f\"Z-score Surface ({udl}) From: {start_date.strftime('%Y-%m-%d')} to: {end_date.strftime('%Y-%m-%d')}\"\n",
    "                styled_df = style_df(zscore_surface, title)\n",
    "                display(styled_df)\n",
    "            else:\n",
    "                print(\"Please select start and end dates for Z-score surface.\")\n",
    "        else:\n",
    "            print(\"Invalid surface type selected.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e} - Ensure the selected date range is within the data's date range.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def format_and_adjust_column_names(df):\n",
    "    formatted_columns = []\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            float_col = float(col)\n",
    "            if float_col.is_integer():\n",
    "                formatted_columns.append(f\"{int(float_col)}\")\n",
    "            else:\n",
    "                formatted_columns.append(f\"{float_col:.1f}\")\n",
    "        except ValueError:\n",
    "            formatted_columns.append(str(col))  # Ensure the column name is a string even if it cannot be converted to float\n",
    "    df.columns = formatted_columns\n",
    "    df.index = [str(idx) for idx in df.index]  # Ensure the index is formatted as strings\n",
    "    return df\n",
    "    \n",
    "import matplotlib.colors as mcolors\n",
    "BNPP_colors = [\n",
    "    (0, 124/256, 177/256), # Blue\n",
    "    (112/256, 194/256, 122/256), # Green\n",
    "    (238/256, 48/256, 46/256) # Red\n",
    "]\n",
    "\n",
    "BNPP_colors_float = [[c/256 for c in color] for color in BNPP_colors]\n",
    "\n",
    "GR_cmap = mcolors.LinearSegmentedColormap.from_list(\"GR_cmap\", [BNPP_colors[1], BNPP_colors[2]], N=256)\n",
    "\n",
    "def style_df(df, caption):\n",
    "    df = format_and_adjust_column_names(df)  # Format and adjust column names\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    df_styled = df.style.background_gradient(cmap=GR_cmap).format(\"{:.1f}\").set_table_styles([\n",
    "        {'selector': 'th', 'props': [('min-width', '90px'), ('max-width', '90px'), ('text-align', 'center')]},\n",
    "        {'selector': 'td', 'props': [('text-align', 'center')]}\n",
    "    ]).set_properties(**{'text-align': 'center'})\n",
    "    \n",
    "    # Add caption and table attributes\n",
    "    df_styled = df_styled.set_caption(caption).set_table_attributes('style=\"width:100%; border-collapse:collapse; border: 1px solid black;\"')\n",
    "    \n",
    "    return df_styled\n",
    "    \n",
    "def ensure_numerical(df):\n",
    "    return df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Function to toggle date widgets visibility\n",
    "def toggle_date_widgets(surface_type):\n",
    "    if surface_type in ['Percentile', 'Z-score']:\n",
    "        start_date_widget.layout.display = 'block'\n",
    "        end_date_widget.layout.display = 'block'\n",
    "        date_widget.layout.display = 'none'\n",
    "    else:\n",
    "        start_date_widget.layout.display = 'none'\n",
    "        end_date_widget.layout.display = 'none'\n",
    "        date_widget.layout.display = 'block'\n",
    "\n",
    "# Function to create a volatility surface\n",
    "def create_vol_surface(nested_dict, date, udl, moneyness_levels):\n",
    "    date_str = date if isinstance(date, str) else date.strftime('%Y-%m-%d')\n",
    "    if date_str not in nested_dict:\n",
    "        raise ValueError(f\"Date {date_str} not found in data.\")\n",
    "\n",
    "    vol_surface = pd.DataFrame(index=moneyness_levels)\n",
    "    for matu, moneyness_data in nested_dict[date_str][udl]['IV'].items():\n",
    "        vol_surface[matu] = [moneyness_data.get(moneyness, \n",
    "                                                np.nan) for moneyness in moneyness_levels]\n",
    "    vol_surface = vol_surface.T\n",
    "    vol_surface.columns = [f'{mon}' for mon in vol_surface.columns]\n",
    "    vol_surface.index.name = 'Maturity'\n",
    "    vol_surface = vol_surface.map(lambda x: round(x, 2) if pd.notna(x) else np.nan)\n",
    "    return vol_surface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d915920-b3b2-44e6-a823-ff8355f356f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b088e8bd-4e04-4b15-b9ac-dea46b448b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2024-01-01'\n",
    "end_date = '2024-05-28'\n",
    "date = '2024-05-21'\n",
    "\n",
    "udl_list = ['JP_NKY', 'DE_DAX', 'GB_FTSE100', 'CH_SMI', 'IT_FTMIB', 'ES_IBEX', 'US_SPX', 'EU_STOXX50E', 'EU_SX7E', 'EU_SX7P',\n",
    "            'EU_SXDP', 'US_KO', 'US_MCD', 'US_KOMO', 'EU_SXPP', 'EU_SOXP', 'HK_HSI']\n",
    "\n",
    "udl =  'EU_STOXX50E'\n",
    "\n",
    "matu_list = [1, 3, 6, 9, 12, 18, 24, 36]\n",
    "moneyness_list = [120, 110, 105, 102.5, 100, 97.5, 95, 90, 80]\n",
    "delta_list = [5, 10, 15, 20, 25, 35, 50, 65, 75, 90, 95]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06d772b-874d-4998-a862-b3b126293fbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Generate data to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdcc6d98-c671-4775-adfe-01c9921ee699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dict\n",
    "path = \"vol_surf.pickle\"\n",
    "with open(path, 'rb') as handle:\n",
    "    nested_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e06d3cb-d79a-4e85-bced-99a8afd29838",
   "metadata": {},
   "source": [
    "### APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef96ddf-68c8-481f-a768-3905ebd55ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdbf5a0199e4273bb75e4a37cc1c574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Dropdown(description='UDL:', options=('JP_NKY', 'DE_DAX', 'GB_FTSâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Widget definitions\n",
    "udl_widget = widgets.Dropdown(\n",
    "    options=udl_list,\n",
    "    value='EU_STOXX50E',\n",
    "    description='UDL:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "date_widget = widgets.DatePicker(\n",
    "    description='Date',\n",
    "    value=pd.to_datetime(end_date),\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "start_date_widget = widgets.DatePicker(\n",
    "    description='Start Date',\n",
    "    value=pd.to_datetime(start_date),\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "end_date_widget = widgets.DatePicker(\n",
    "    description='End Date',\n",
    "    value=pd.to_datetime(end_date),\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "surface_type_widget = widgets.Dropdown(\n",
    "    options=['Level', 'Percentile', 'Z-score'],\n",
    "    value='Level',\n",
    "    description='Type:',\n",
    "    disabled=False,\n",
    ")\n",
    "# Widgets\n",
    "udl_widget = widgets.Dropdown(options=udl_list, description='UDL:')\n",
    "surface_type_widget = widgets.Dropdown(options=['Level', 'Percentile', 'Z-score'], description='Type:')\n",
    "date_widget = widgets.DatePicker(description='Date', value=pd.to_datetime('2024-05-28'))\n",
    "start_date_widget = widgets.DatePicker(description='Start Date', value=pd.to_datetime('2024-01-01'))\n",
    "end_date_widget = widgets.DatePicker(description='End Date', value=pd.to_datetime('2024-05-27'))\n",
    "\n",
    "# Observe changes in surface type to toggle date widgets\n",
    "surface_type_widget.observe(lambda change: toggle_date_widgets(change['new']), names='value')\n",
    "\n",
    "# Create interactive output\n",
    "output = widgets.interactive_output(plot_surface, {\n",
    "    'udl': udl_widget, \n",
    "    'date': date_widget,\n",
    "    'surface_type': surface_type_widget,\n",
    "    'start_date': start_date_widget,\n",
    "    'end_date': end_date_widget\n",
    "})\n",
    "\n",
    "\n",
    "# Layout for widgets\n",
    "left_box = widgets.VBox([udl_widget, surface_type_widget], layout=widgets.Layout(margin='10px'))\n",
    "right_box = widgets.VBox([start_date_widget, end_date_widget, date_widget], layout=widgets.Layout(margin='10px'))\n",
    "top_box = widgets.HBox([left_box, right_box], layout=widgets.Layout(justify_content='space-between', align_items='center', margin='10px'))\n",
    "main_box = widgets.VBox([top_box, output])\n",
    "\n",
    "# Set initial visibility\n",
    "toggle_date_widgets(surface_type_widget.value)\n",
    "\n",
    "# Display the widgets and output\n",
    "display(main_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e532d77-4513-4bc3-8435-1c1d94772863",
   "metadata": {},
   "source": [
    "### Scheduled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b92f21c-4dc1-4cc3-a3ac-1fe8e90412db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install schedule\n",
    "import warnings\n",
    "\n",
    "# Suppress the specific FutureWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import schedule\n",
    "import time\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from vol_data import *\n",
    "from surface import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e56b742d-047f-4a96-aa06-51057dfefd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your parameters\n",
    "spe_time = \"22:48\"\n",
    "\n",
    "start_date = '2024-01-01'\n",
    "end_date = '2024-05-28'\n",
    "\n",
    "udl_list = ['JP_NKY', 'DE_DAX', 'GB_FTSE100', 'CH_SMI', 'IT_FTMIB', 'ES_IBEX', 'US_SPX', 'EU_STOXX50E', 'EU_SX7E', 'EU_SX7P',\n",
    "            'EU_SXDP', 'US_KO', 'US_MCD', 'US_KOMO', 'EU_SXPP', 'EU_SOXP', 'HK_HSI']\n",
    "\n",
    "matu_list = [1, 3, 6, 9, 12, 18, 24, 36]\n",
    "moneyness_list = [120, 110, 105, 102.5, 100, 97.5, 95, 90, 80]\n",
    "delta_list = [5, 10, 15, 20, 25, 35, 50, 65, 75, 90, 95]\n",
    "\n",
    "path = \"vol_surf.pickle\"  # Path to save the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7129cd-d03e-4933-8022-ba44bc6a39b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vol_moneyness(udl_list, matu_list, moneyness_list, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generate random volatility moneyness data.\n",
    "    \"\"\"\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "    data = {\n",
    "        (udl, matu, mon): np.random.rand(len(date_range)) * 100\n",
    "        for udl in udl_list\n",
    "        for matu in matu_list\n",
    "        for mon in moneyness_list\n",
    "    }\n",
    "    df = pd.DataFrame(data, index=date_range)\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.columns, names=['udl', 'matu', 'moneyness'])\n",
    "    return df\n",
    "\n",
    "def get_vol_delta(udl_list, matu_list, delta_list, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generate random volatility delta data.\n",
    "    \"\"\"\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "    data = {\n",
    "        (udl, matu, delta): np.random.rand(len(date_range)) * 100\n",
    "        for udl in udl_list\n",
    "        for matu in matu_list\n",
    "        for delta in delta_list\n",
    "    }\n",
    "    df = pd.DataFrame(data, index=date_range)\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.columns, names=['udl', 'matu', 'delta'])\n",
    "    return df\n",
    "    \n",
    "def generate_table(udl_list, matu_list, moneyness_list, delta_list, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generate random volatility data for moneyness and delta in a single step and create a structured DataFrame.\n",
    "\n",
    "    Args:\n",
    "        udl_list (list): List of underlying assets.\n",
    "        matu_list (list): List of maturities.\n",
    "        moneyness_list (list): List of moneyness levels.\n",
    "        delta_list (list): List of delta levels.\n",
    "        start_date (str): Start date for the data.\n",
    "        end_date (str): End date for the data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with combined moneyness and delta data, indexed by date with MultiIndex columns.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date_range = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "\n",
    "        # Generate moneyness and delta data\n",
    "        df_vol_moneyness = get_vol_moneyness(udl_list, matu_list, moneyness_list, start_date, end_date)\n",
    "        df_vol_delta = get_vol_delta(udl_list, matu_list, delta_list, start_date, end_date)\n",
    "\n",
    "        data = {}\n",
    "\n",
    "        # Combine moneyness data\n",
    "        for udl in udl_list:\n",
    "            for matu in matu_list:\n",
    "                for mon in moneyness_list:\n",
    "                    key = (udl, matu, mon)\n",
    "                    data[(udl, 'IV', matu, mon)] = df_vol_moneyness[key]\n",
    "\n",
    "        # Combine delta data\n",
    "        for udl in udl_list:\n",
    "            for matu in matu_list:\n",
    "                for delta in delta_list:\n",
    "                    key = (udl, matu, delta)\n",
    "                    data[(udl, 'IVFD', matu, delta)] = df_vol_delta[key]\n",
    "\n",
    "        df = pd.DataFrame(data, index=date_range)\n",
    "        df.columns = pd.MultiIndex.from_tuples(df.columns, names=['udl', 'param', 'matu', 'value'])\n",
    "        df.index.name = 'Date'\n",
    "        df.ffill(inplace=True)\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during table generation: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def df_to_nested_dict(df):\n",
    "    nested_dict = {}\n",
    "    for date, row in df.iterrows():\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        nested_dict[date_str] = {}\n",
    "        for col, val in row.items():\n",
    "            udl, param, matu, value = col\n",
    "            nested_dict[date_str].setdefault(udl, {}).setdefault(param, {}).setdefault(matu, {})[value] = val\n",
    "    return nested_dict\n",
    "\n",
    "def generate_and_save_vol_surf():\n",
    "    try:\n",
    "        # Generate the table\n",
    "        df = generate_table(udl_list, matu_list, moneyness_list, delta_list, start_date, end_date)\n",
    "\n",
    "        # Convert DataFrame to nested dictionary\n",
    "        nested_dict = df_to_nested_dict(df)\n",
    "\n",
    "        # Save the nested dictionary to a pickle file\n",
    "        with open(path, 'wb') as handle:\n",
    "            pickle.dump(nested_dict, handle)\n",
    "\n",
    "        print(f\"{datetime.now()} - Volatility surface data generated and saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def run_schedule():\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(1)  # Wait a bit before checking again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58f16573-4ec1-410b-b1a8-64abb613f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule the job to run at midnight every day\n",
    "schedule.every().day.at(spe_time).do(generate_and_save_vol_surf)\n",
    "\n",
    "# Start the scheduler in a new thread\n",
    "scheduler_thread = threading.Thread(target=run_schedule, daemon=True)\n",
    "scheduler_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1d7364-439c-4e6a-b246-16d62f50c3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler started. The task will run every day at: 22:48\n"
     ]
    }
   ],
   "source": [
    "print(\"Scheduler started. The task will run every day at: \" + spe_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb599c88-633c-4be3-a2d1-df65fbac3c48",
   "metadata": {},
   "source": [
    "### DEV\n",
    "\n",
    "Added/Updated Data Generation Functions: These functions remain the same since we are using the same method to generate random volatility data. No changes were needed here.\n",
    "\n",
    "get_vol_moneyness\n",
    "get_vol_delta\n",
    "generate_table\n",
    "Adjusted Calculation Functions: These functions were updated to calculate the spread between two UDLs.\n",
    "\n",
    "calculate_percentile_rank_surface\n",
    "calculate_zscore_surface\n",
    "create_vol_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b57e4dfa-0fb2-4865-894d-8a3e56bf4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentile_rank_surface(nested_dict, udl1, udl2, date, moneyness_levels):\n",
    "    try:\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        percentile_rank_surface = pd.DataFrame(index=moneyness_levels, columns=nested_dict[date_str][udl1]['IV'].keys())\n",
    "\n",
    "        for matu in percentile_rank_surface.columns:\n",
    "            for mon in moneyness_levels:\n",
    "                try:\n",
    "                    values = []\n",
    "                    for past_date in nested_dict:\n",
    "                        if (udl1 in nested_dict[past_date] and 'IV' in nested_dict[past_date][udl1] and \n",
    "                            matu in nested_dict[past_date][udl1]['IV'] and mon in nested_dict[past_date][udl1]['IV'][matu] and\n",
    "                            udl2 in nested_dict[past_date] and 'IV' in nested_dict[past_date][udl2] and \n",
    "                            matu in nested_dict[past_date][udl2]['IV'] and mon in nested_dict[past_date][udl2]['IV'][matu]):\n",
    "                            spread = nested_dict[past_date][udl1]['IV'][matu][mon] - nested_dict[past_date][udl2]['IV'][matu][mon]\n",
    "                            values.append(spread)\n",
    "                    if len(values) > 0:\n",
    "                        current_value = nested_dict[date_str][udl1]['IV'][matu][mon] - nested_dict[date_str][udl2]['IV'][matu][mon]\n",
    "                        percentile = percentileofscore(values, current_value, kind='mean')\n",
    "                        percentile_rank_surface.at[mon, matu] = percentile\n",
    "                    else:\n",
    "                        percentile_rank_surface.at[mon, matu] = np.nan\n",
    "                except KeyError:\n",
    "                    percentile_rank_surface.at[mon, matu] = np.nan\n",
    "\n",
    "        return percentile_rank_surface.T\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in calculate_percentile_rank_surface: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def calculate_zscore_surface(nested_dict, udl1, udl2, date, moneyness_levels):\n",
    "    try:\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        zscore_surface = pd.DataFrame(index=moneyness_levels, columns=nested_dict[date_str][udl1]['IV'].keys())\n",
    "\n",
    "        for matu in zscore_surface.columns:\n",
    "            for mon in moneyness_levels:\n",
    "                try:\n",
    "                    values = []\n",
    "                    for past_date in nested_dict:\n",
    "                        if (udl1 in nested_dict[past_date] and 'IV' in nested_dict[past_date][udl1] and \n",
    "                            matu in nested_dict[past_date][udl1]['IV'] and mon in nested_dict[past_date][udl1]['IV'][matu] and\n",
    "                            udl2 in nested_dict[past_date] and 'IV' in nested_dict[past_date][udl2] and \n",
    "                            matu in nested_dict[past_date][udl2]['IV'] and mon in nested_dict[past_date][udl2]['IV'][matu]):\n",
    "                            spread = nested_dict[past_date][udl1]['IV'][matu][mon] - nested_dict[past_date][udl2]['IV'][matu][mon]\n",
    "                            values.append(spread)\n",
    "                    if len(values) > 0:\n",
    "                        mean = np.mean(values)\n",
    "                        std = np.std(values, ddof=1)\n",
    "                        current_value = nested_dict[date_str][udl1]['IV'][matu][mon] - nested_dict[date_str][udl2]['IV'][matu][mon]\n",
    "                        if std > 0:\n",
    "                            zscore = (current_value - mean) / std\n",
    "                            zscore_surface.at[mon, matu] = zscore\n",
    "                        else:\n",
    "                            zscore_surface.at[mon, matu] = np.nan\n",
    "                    else:\n",
    "                        zscore_surface.at[mon, matu] = np.nan\n",
    "                except KeyError:\n",
    "                    zscore_surface.at[mon, matu] = np.nan\n",
    "\n",
    "        return zscore_surface.T\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in calculate_zscore_surface: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def create_vol_surface(nested_dict, date, udl1, udl2, moneyness_levels):\n",
    "    date_str = date if isinstance(date, str) else date.strftime('%Y-%m-%d')\n",
    "    if date_str not in nested_dict:\n",
    "        raise ValueError(f\"Date {date_str} not found in data.\")\n",
    "\n",
    "    vol_surface = pd.DataFrame(index=moneyness_levels)\n",
    "    for matu, moneyness_data in nested_dict[date_str][udl1]['IV'].items():\n",
    "        vol_surface[matu] = [\n",
    "            moneyness_data.get(moneyness, np.nan) - nested_dict[date_str][udl2]['IV'][matu].get(moneyness, np.nan)\n",
    "            for moneyness in moneyness_levels\n",
    "        ]\n",
    "    vol_surface = vol_surface.T\n",
    "    vol_surface.columns = [f'{mon}' for mon in vol_surface.columns]\n",
    "    vol_surface.index.name = 'Maturity'\n",
    "    vol_surface = vol_surface.applymap(lambda x: round(x, 2) if pd.notna(x) else np.nan)\n",
    "    return vol_surface\n",
    "\n",
    "def plot_surface(udl1, udl2, date, surface_type, start_date=None, end_date=None):\n",
    "    try:\n",
    "        date = pd.Timestamp(date)\n",
    "\n",
    "        if surface_type == 'Level':\n",
    "            vol_surface = create_vol_surface(nested_dict, date, udl1, udl2, moneyness_list)\n",
    "            vol_surface = ensure_numerical(vol_surface)  # Ensure numerical format\n",
    "            display(style_df(vol_surface, f\"Volatility Spread Surface ({udl1} - {udl2})\"))\n",
    "        elif surface_type == 'Percentile':\n",
    "            if start_date and end_date:\n",
    "                start_date = pd.Timestamp(start_date)\n",
    "                end_date = pd.Timestamp(end_date)\n",
    "                if start_date > end_date:\n",
    "                    print(\"Start date cannot be after end date.\")\n",
    "                    return\n",
    "                filtered_dict = {k: v for k, v in nested_dict.items() if start_date <= pd.Timestamp(k) <= end_date}\n",
    "                percentile_surface = calculate_percentile_rank_surface(filtered_dict, udl1, udl2, end_date, moneyness_list)\n",
    "                percentile_surface = ensure_numerical(percentile_surface)  # Ensure numerical format\n",
    "                title = f\"Percentile Spread Surface ({udl1} - {udl2}) From: {start_date.strftime('%Y-%m-%d')} to: {end_date.strftime('%Y-%m-%d')}\"\n",
    "                styled_df = style_df(percentile_surface, title)\n",
    "                display(styled_df)\n",
    "            else:\n",
    "                print(\"Please select start and end dates for Percentile surface.\")\n",
    "        elif surface_type == 'Z-score':\n",
    "            if start_date and end_date:\n",
    "                start_date = pd.Timestamp(start_date)\n",
    "                end_date = pd.Timestamp(end_date)\n",
    "                if start_date > end_date:\n",
    "                    print(\"Start date cannot be after end date.\")\n",
    "                    return\n",
    "                filtered_dict = {k: v for k, v in nested_dict.items() if start_date <= pd.Timestamp(k) <= end_date}\n",
    "                zscore_surface = calculate_zscore_surface(filtered_dict, udl1, udl2, end_date, moneyness_list)\n",
    "                zscore_surface = ensure_numerical(zscore_surface)  # Ensure numerical format\n",
    "                title = f\"Z-score Spread Surface ({udl1} - {udl2}) From: {start_date.strftime('%Y-%m-%d')} to: {end_date.strftime('%Y-%m-%d')}\"\n",
    "                styled_df = style_df(zscore_surface, title)\n",
    "                display(styled_df)\n",
    "            else:\n",
    "                print(\"Please select start and end dates for Z-score surface.\")\n",
    "        else:\n",
    "            print(\"Invalid surface type selected.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e} - Ensure the selected date range is within the data's date range.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f4aa3d9-a6f2-4b7c-9187-77cbc6deb27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d080b1987c6448f90fc00db747d06b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Dropdown(description='UDL1:', options=('JP_NKY', 'DE_DAX', 'GB_FTâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Widgets for selecting UDLs, dates, and surface types\n",
    "udl1_widget = widgets.Dropdown(options=udl_list, description='UDL1:')\n",
    "udl2_widget = widgets.Dropdown(options=udl_list, description='UDL2:')\n",
    "surface_type_widget = widgets.Dropdown(options=['Level', 'Percentile', 'Z-score'], description='Type:')\n",
    "date_widget = widgets.DatePicker(description='Date', value=pd.to_datetime(end_date))\n",
    "start_date_widget = widgets.DatePicker(description='Start Date', value=pd.to_datetime(start_date))\n",
    "end_date_widget = widgets.DatePicker(description='End Date', value=pd.to_datetime(end_date))\n",
    "\n",
    "# Observe changes in surface type to toggle date widgets\n",
    "surface_type_widget.observe(lambda change: toggle_date_widgets(change['new']), names='value')\n",
    "\n",
    "# Function to toggle date widgets visibility\n",
    "def toggle_date_widgets(surface_type):\n",
    "    if surface_type in ['Percentile', 'Z-score']:\n",
    "        start_date_widget.layout.display = 'block'\n",
    "        end_date_widget.layout.display = 'block'\n",
    "        date_widget.layout.display = 'none'\n",
    "    else:\n",
    "        start_date_widget.layout.display = 'none'\n",
    "        end_date_widget.layout.display = 'none'\n",
    "        date_widget.layout.display = 'block'\n",
    "\n",
    "# Function to ensure numerical format\n",
    "def ensure_numerical(df):\n",
    "    return df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Create interactive output\n",
    "output = widgets.interactive_output(plot_surface, {\n",
    "    'udl1': udl1_widget, \n",
    "    'udl2': udl2_widget,\n",
    "    'date': date_widget,\n",
    "    'surface_type': surface_type_widget,\n",
    "    'start_date': start_date_widget,\n",
    "    'end_date': end_date_widget\n",
    "})\n",
    "\n",
    "# Layout for widgets\n",
    "left_box = widgets.VBox([udl1_widget, udl2_widget, surface_type_widget], layout=widgets.Layout(margin='10px'))\n",
    "right_box = widgets.VBox([start_date_widget, end_date_widget, date_widget], layout=widgets.Layout(margin='10px'))\n",
    "top_box = widgets.HBox([left_box, right_box], layout=widgets.Layout(justify_content='space-between', align_items='center', margin='10px'))\n",
    "main_box = widgets.VBox([top_box, output])\n",
    "\n",
    "# Set initial visibility\n",
    "toggle_date_widgets(surface_type_widget.value)\n",
    "\n",
    "# Display the widgets and output\n",
    "display(main_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3af1fd-1468-4a30-a772-5e73de7b1013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
